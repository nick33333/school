{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "########################################################################\n",
    "# File: Chan_Nicholas_randomizedMotifSearch.ipynb\n",
    "# Purpose: to find the promoter motif\n",
    "#   main(infile='FILE_PATH',outfile='FILE_PATH', inCL=['-i 1000', '-p 1', '-k 13'])\n",
    "#\n",
    "# Author: Nicholas Chan\n",
    "# History: 10/10/2021 Created\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Class\n",
    "Provided by Dr. B for parsing command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# CommandLine\n",
    "########################################################################\n",
    "\n",
    "\n",
    "class CommandLine():\n",
    "    \"\"\"\n",
    "    Handle the command line, usage and help requests.\n",
    "\n",
    "    CommandLine uses argparse,\n",
    "    it implements a standard command line argument parser with various argument options,\n",
    "    a standard usage and help, and an error termination exception Usage.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inOpts = None):\n",
    "        \"\"\"\n",
    "        CommandLine constructor.\n",
    "        \n",
    "        Implement a parser to interpret the command line argv string using argparse.\n",
    "        \"\"\"\n",
    "        import argparse\n",
    "        self.parser = argparse.ArgumentParser(\n",
    "            description='Program prolog - a brief description of what this thing does',\n",
    "            epilog='Program epilog - some other stuff you feel compelled to say',\n",
    "            add_help=True,  # default is True\n",
    "            prefix_chars='-',\n",
    "            usage='%(prog)s [options] -option1[default] <input >output'\n",
    "            )\n",
    "\n",
    "        self.parser.add_argument('-i', '--iterations', type=int, default=1000, action='store', help='number of times of iterations to find consensus motif')\n",
    "        self.parser.add_argument('-k', '--motifLength', type=int, default=13, action='store', help='length of the target promoter motif')\n",
    "        self.parser.add_argument('-p', '--pseudocount', type=float, default=1, action='store', help='number of pseudocounts')\n",
    "        # Command line option to use Gibbs sampling to find the optimal consensus motif.\n",
    "#         self.parser.add_argument('-g', '--gibbsampling', type=float, default=1, action='store', help='implement Gibbs sampling')\n",
    "\n",
    "        if inOpts is None:\n",
    "            self.args = self.parser.parse_args()\n",
    "        else:\n",
    "            self.args = self.parser.parse_args(inOpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAreader Class\n",
    "Provided by Dr. B for reading Fasta Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "class FastAreader():\n",
    "    \"\"\"\n",
    "    Read in files and preprocess.\n",
    "    \"\"\"\n",
    "    def __init__(self, fname=''):\n",
    "        \"\"\" Contructor: saves attribute fname. \"\"\"\n",
    "        self.fname = fname\n",
    "\n",
    "    def doOpen(self):\n",
    "        \"\"\" Open a file.\"\"\"\n",
    "        if self.fname == '':\n",
    "            return sys.stdin\n",
    "        else:\n",
    "            return open(self.fname)\n",
    "\n",
    "    def readFasta(self):\n",
    "        \"\"\" Read in a fasta file and yield header and sequences separately\"\"\"\n",
    "        header = ''\n",
    "        sequence = ''\n",
    "\n",
    "        with self.doOpen() as fileH:\n",
    "\n",
    "            header = ''\n",
    "            sequence = ''\n",
    "\n",
    "            # skip to first fasta header\n",
    "            line = fileH.readline()\n",
    "            while not line.startswith('>'):\n",
    "                line = fileH.readline()\n",
    "            header = line[1:].rstrip()\n",
    "\n",
    "            # Separate headers and sequences\n",
    "            for line in fileH:\n",
    "                if line.startswith('>'):\n",
    "                    yield header, sequence\n",
    "                    header = line[1:].rstrip()\n",
    "                    sequence = ''\n",
    "                else:\n",
    "                    sequence += ''.join(line.rstrip().split()).upper()\n",
    "\n",
    "        yield header, sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: CRISPR Promoter Sequences\n",
    "\n",
    "For this assignment I used the Random Motif Search algorithm described by Dr. B and Chapter 2 of Binf. Algorithms. The goal of this \n",
    "assignment was to identify likely motifs in given sequences which could be DnaA binding sites. This algorithm first gathers information\n",
    "on the base composition of all given sequences to create a NULL model to be compared to our experimental models. Our experimental models\n",
    "first start out as a list of randomly selected motifs of size k. From there, an initial profile matrix is made (including pseudo counts\n",
    "if any). We then grab all possible k-mer permutations in each sequence and apply our newly made profile matrix to develop a new set of \n",
    "motifs. With a new set of motifs, we are able to make a new profile matrix. We can compare the relative entropy scores between our initial \n",
    "model and our new model made from the previous profile matrix. If the Relatvie Entropy score of our new model is higher than the previous,\n",
    "we continue making new models from previous models. Else we stop and return the consensus sequence and Relative Entropy score from the \n",
    "best performing model.\n",
    "\n",
    "## Shannon's Entropy\n",
    "$H(x) = -\\sum_{i = 1}^{n} P(x_{i}) log_{2} (P(x_{i}))$ \n",
    "<br/>\n",
    "$H(x) = -\\sum_{i \\in [A,C,G,T]} P(x_{i}) log_{2} (P(x_{i}))$\n",
    "- An encoding cost\n",
    "\n",
    "## Relative Entropy\n",
    "$D_{KL}(P||Q) = \\sum_{i \\in [A,C,G,T]} P(x_{i}) log_{2} \\frac{P(x_{i})} {Q(x_{i})}$\n",
    "- A distance between 2 profile probability distributions\n",
    "- P and Q are 2 probability profile distributions\n",
    "- We look at the log of a ratio of 2 probabilities (a comparison)\n",
    "- We want to compare our observed profile to just the base composition of all our sequences\n",
    "- Model Q is our NULL model\n",
    "    - This is the probability of each of our 4 bases\n",
    "- Model P describes our experimental model\n",
    "    - This is the probability of each of our 4 bases in our selected motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "# Handle iterations i in main function\n",
    "class RandomMotifSearch():\n",
    "    '''\n",
    "    The RandomMotifSearch class finds the null model, possible k-mers, probability profile,\n",
    "    likely motifs of size k, and relative entropy scores of profiles of a given set of sequences.\n",
    "    All these can be returned individually with a call to a RandomMotifSearch object. An object \n",
    "    of RandomMotifSearch requires k: length of a motif to search for, p: number of pseudo counts,\n",
    "    seqList: list of sequences from a fasta file (FastAreader ouput), and seqString: a string of all \n",
    "    the sequences from a fasta file (FastAreader ouput). \n",
    "    '''\n",
    "    def __init__(self, k:'int', p:'int', seqList:'list', seqString:'str'):\n",
    "        self.p = p # Pseudo counts\n",
    "        self.k = k # k-mer length\n",
    "        self.seqList = seqList # List of input sequences\n",
    "        self.seqString = seqString # String of all input sequences\n",
    "        \n",
    "        self.nullModel = self.nullMod() # Null model generated from collection of all sequences\n",
    "        self.kmerPermutations = self.generateKMerPerms() # A list of lists of k-mer permutations of size k from a sequence\n",
    "        self.motifList = self.motifify() # First motif list, use reMotifify to generate a new lsit\n",
    "        self.profileMatrix = self.profilify() # First motif profile matrix, use profilify again with a new motif list to generate a new profile\n",
    "        self.REscore = self.bestProfile() # Best recorded RE Score from the current motif probability profile\n",
    "\n",
    "    def nullMod(self) -> 'dict()':\n",
    "        '''\n",
    "        Returns null model with pseudocounts.\n",
    "        '''\n",
    "        nullProfDict = dict()\n",
    "        countA = self.seqString.count('A')\n",
    "        countC = self.seqString.count('C')\n",
    "        countG = self.seqString.count('G')\n",
    "        countT = self.seqString.count('T')\n",
    "        countTot = countA + countC + countG + countT\n",
    "        nullProfDict['A'] = (countA + self.p)/(countTot + self.p*4)\n",
    "        nullProfDict['C'] = (countC + self.p)/(countTot + self.p*4)\n",
    "        nullProfDict['G'] = (countG + self.p)/(countTot + self.p*4)\n",
    "        nullProfDict['T'] = (countT + self.p)/(countTot + self.p*4)\n",
    "        return nullProfDict\n",
    "    \n",
    "    def motifify(self) -> 'list': # Randomly generates motifs, independent\n",
    "        ''' \n",
    "        Params: (self.seqList: 'list', self.k: 'int of motif length')\n",
    "        Generates n number of sequences of length k (list of k-mers/motifs). \n",
    "        In other worrds, makes a list of randomly selected \n",
    "        k-mers/motifs from given list of seqs.\n",
    "        '''\n",
    "        motifs = []\n",
    "        for seq in self.seqList: # Can be read as for each sequence in the given fasta file\n",
    "            indexRange = np.random.randint(0,len(seq)-self.k) # Sets a valid range for randomly pulling k-mers from a sequence \n",
    "            motifs.append(seq[indexRange:indexRange + self.k]) # Randomly selects a motif from a sequence and appends it to a list\n",
    "        return motifs # Returns a list of motifs, 1 motif per sequence in fasta file\n",
    "    \n",
    "    # Counts check out, all columns add up to 1 and fractions match decimals\n",
    "    def profilify(self) -> 'dict(lists)': # Independent\n",
    "        ''' \n",
    "        Params: (motifList: 'list', p:'int'=0)\n",
    "        Generates a profile matrix given a list of k-mers/motifs.\n",
    "        Pseudocounts are added into the Experimental and NULL models\n",
    "        in this method.\n",
    "        '''\n",
    "        # A-C-G-T correspond to 0-1-2-3\n",
    "        matRowCount = len(self.motifList)\n",
    "        motifLength = len(self.motifList[0])\n",
    "        # Dictionary matrix where rows are bases [A,C,T,G] and cols are motif indices\n",
    "        profileMatrix = dict(A=np.array([0]*motifLength), C=np.array([0]*motifLength), T=np.array([0]*motifLength), G=np.array([0]*motifLength))\n",
    "        for motif in self.motifList: # Iterate first over motifs in motif list (input)\n",
    "            idx=0 # Keep index of motif positions\n",
    "            for base in motif: # Iterate over motif bases\n",
    "                profileMatrix[base][idx]+=1\n",
    "                idx+=1\n",
    "        if self.p > 0: # If there are pseudocounts to be added\n",
    "            for key in profileMatrix.keys():\n",
    "                profileMatrix[key] = np.divide(profileMatrix[key] + self.p, matRowCount + (self.p*4)) # divides a list of motif base frequencies + pseudocount p by total bases per index + pseudocounts p*4\n",
    "            return profileMatrix\n",
    "        # If pseudocounts are 0, might not need em\n",
    "        else: # If there are no pseudocounts to be added\n",
    "            for key in profileMatrix.keys():\n",
    "                profileMatrix[key] = np.divide(profileMatrix[key],matRowCount) # divides a list of motif base frequencies by total bases per index\n",
    "            return profileMatrix  \n",
    "        \n",
    "    def findProb(self, kmer:'str') -> 'float':\n",
    "        ''' \n",
    "        Params: (profileMatrix:'dict(lists)',kmer:'str')\n",
    "        Finds the probability of a whole k-mer given a Profile.\n",
    "        Find individual probabilities of each base in motif and finds product from each position.\n",
    "        '''\n",
    "        totProb = 1\n",
    "        for idx in range(len(kmer)): # Counts through each base position in the k-mer\n",
    "            totProb *= self.profileMatrix[kmer[idx]][idx] \n",
    "        return totProb # Returns the product of all base probabilities in a k-mer (a k-mer's likelihood)\n",
    "    \n",
    "    def generateKMerPerms(self) -> 'list[lists]': \n",
    "        ''' \n",
    "        Params: (seqList: 'List of raw sequences', k: 'int of k-mer length')\n",
    "        Generates a list of lists of all k-mer permutations from raw sequences \n",
    "        '''\n",
    "        kmerMat = []\n",
    "        for seq in self.seqList: # Goes through each sequence from the input\n",
    "            kmerList = []\n",
    "            for idx in range(len(seq)-self.k): # Uses sliding frame method to collect all possible k-mers in a sequence\n",
    "                kmerList.append(seq[idx:idx+self.k])\n",
    "            kmerMat.append(kmerList)\n",
    "        return kmerMat # Returns a list of all possible k-mers per sequence\n",
    "    \n",
    "    def reMotifify(self) -> 'list of k-mers with the maximum probs':\n",
    "        ''''\n",
    "        Params: (kmerPermutations:'list of lists, profileMatrix:'4 x k dict of probabilities')\n",
    "        Same type of output as motifify.\n",
    "        Use this to generate motifs with maximum likelihood after initial random motif generation.\n",
    "        A PERMUTATION MATRIX IS READ IN (list of lists)\n",
    "        Each row contains all possible motif permutations per given sequence.\n",
    "        '''\n",
    "        maxPermList = []\n",
    "        for permList in self.kmerPermutations:\n",
    "            probList = []\n",
    "            for perm in permList:\n",
    "                probList.append(self.findProb(perm)) # Calculates probability of a motif given a profile and appends the probability\n",
    "            maxPermList.append(permList[probList.index(max(probList))]) # Finds index of the motif with the highest probability in a PERMUTATION LIST and appends the permutation to maxPermList\n",
    "        return maxPermList\n",
    "\n",
    "    def findConsensus(self): # Can be called at end AFTER calling rms.bestProfile()\n",
    "        '''\n",
    "        Params: (profMat:'dict of np arrays')\n",
    "        Finds a consensus sequence from the current profile matrix.\n",
    "        '''\n",
    "        motifLength = len(self.profileMatrix['A'])\n",
    "        baseList = ['A','C','T','G']\n",
    "        conSeq = ''\n",
    "        for idx in range(motifLength):\n",
    "            baseColList = []\n",
    "            for base in baseList:\n",
    "                baseColList.append((base,self.profileMatrix[base][idx]))\n",
    "            baseColList.sort(key=lambda x:x[1])\n",
    "            conSeq += baseColList[::-1][0][0] # Way of getting to value as baseColList looks like [['A',1],['B',2], ...,['F',6]]\n",
    "        return conSeq\n",
    "    \n",
    "    def relativeEntropy(self, expModel:'dict(lists)'):\n",
    "        '''\n",
    "        Exp model is the profile matrix you want to score.\n",
    "        This method calculates the relative entropy score of a profile matrix.\n",
    "        '''\n",
    "        colLen = len(expModel['A'])\n",
    "        bases = ['A', 'T', 'C', 'G']\n",
    "        fullPart = []# list for sum of cols of RE eq\n",
    "        for col in range(colLen): # calculation for RE for 1 column\n",
    "            basePart = [] # list for inner sum of RE eq\n",
    "            for base in bases: # calculation for RE for 1 base\n",
    "                frac = expModel[base][col]/self.nullModel[base]\n",
    "                logged = np.log2(frac)\n",
    "                bpart = expModel[base][col]*logged\n",
    "                basePart.append(bpart)\n",
    "            fullPart.append(sum(basePart))\n",
    "        return sum(fullPart)       \n",
    "    \n",
    "    def bestProfile(self):\n",
    "        '''\n",
    "        This method iteratively improves the approximation of our \n",
    "        profile matrix and RE Score. Profile matrices are iteratively\n",
    "        made form preexisting ones until RE Score no longer improves.\n",
    "        '''\n",
    "        RE = self.relativeEntropy(self.profileMatrix) # Saves previous RE Score\n",
    "        diff = 0 # Saves a value for difference between Prev and Curr RE Scores\n",
    "        First = True # Special condition for First\n",
    "        while (diff > 0.0 or First):\n",
    "            self.motifList = self.reMotifify() # Builds a new motif list with the existing profile matrix\n",
    "            self.profileMatrix = self.profilify() # Builds a new profile matrix to replace the existing one\n",
    "            First = False # Method is no longer in First state\n",
    "            diff = self.relativeEntropy(self.profileMatrix) - RE # Creates a new difference between the previous and new existing RE Scores\n",
    "            RE = self.relativeEntropy(self.profileMatrix) # Sets the existing RE Score to the newest one\n",
    "        return RE # Returns RE Score when no further change occurs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function \n",
    "Main function is written here. This function handles argument parsing, input, and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(infile, outfile='', inCL=None):\n",
    "    '''\n",
    "    This is the main function. Arguments are parsed here with the CommandLine class\n",
    "    provided by Dr. B. Infile and outfile are also read here, with an outfile file being \n",
    "    optional. IF no outfile is provided, output is printed. Infile is read in through the\n",
    "    readData function which returns fasta file information for the RandomMotifSearch to read.\n",
    "    This way, input only needs to be read once. RandomMotifSearch is called i number of times,\n",
    "    with the relative entropy score and consensus sequence being stored in the motifAndScore list.\n",
    "    The highest RE Score and its corresponding consensus sequence are written to outup.\n",
    "    '''\n",
    "    myCommandLine = CommandLine(inCL)\n",
    "    i = myCommandLine.args.iterations\n",
    "    k = myCommandLine.args.motifLength\n",
    "    p = myCommandLine.args.pseudocount\n",
    "    \n",
    "    def readData(infile:'str') -> 'tuple(list,str)':\n",
    "        '''\n",
    "        Reads in fasta file as input. \n",
    "        Returns [0]: a list of seqs [1]: a string of catted seqs.\n",
    "        '''\n",
    "        seqList = []\n",
    "        readData = FastAreader(infile).readFasta()\n",
    "        for line in readData:\n",
    "            seqList.append(line[1]) # Append seq and not head to seqList\n",
    "        seqString = ''.join(seqList) # After all seq lines have been added to seqList, cat all into 1 str\n",
    "        return (seqList,seqString)\n",
    "    \n",
    "    data = readData(infile) # Saves output of FastAreader(infile).readFasta() as (seqList,seqString)\n",
    "    seqList = data[0] # Saves a list of sequences\n",
    "    seqString = data[1] # Saves a string of sequences\n",
    "    \n",
    "    motifAndScore = [] # Collects consensus sequences and RE Scores for each run of RandomMotifSearch()\n",
    "    for idx in range(i):\n",
    "        myRandomMotifSearch = RandomMotifSearch(k, p, seqList,seqString) # Each call of RandomMotifSearch() starts with a non-deterministic random motif selection step\n",
    "        motifAndScore.append([myRandomMotifSearch.bestProfile(), myRandomMotifSearch.findConsensus()]) \n",
    "    motifAndScore.sort(key=lambda x:x[0]) # Sort list in ascending order by RE Score\n",
    "    \n",
    "    if len(outfile) > 0:\n",
    "        with open(outfile, 'w') as myfile:\n",
    "            myfile.write(f\"{motifAndScore[-1][1]}\\t{motifAndScore[-1][0]}\")\n",
    "    else:\n",
    "        print(f\"{motifAndScore[-1][1]}\\t{motifAndScore[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAAAGAAAAACTT\t7.783555496977213\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    '''\n",
    "    This is where the main function is executed.\n",
    "    Usage:\n",
    "        main(infile='FILE_PATH', outfile='FILE_PATH', inCL=[-ipk] )\n",
    "    Arguments:\n",
    "        -i\n",
    "            Number of RandomMotifSearch iterations\n",
    "        -p\n",
    "            Number of pseudo counts\n",
    "        -k\n",
    "            Length of motif to search for\n",
    "    '''\n",
    "    main(infile='Data/pcaCrisprs',outfile='', inCL=['-i 1000', '-p 1', '-k 13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECTION\n",
    "\n",
    "# INSPECTION TEAM\n",
    "# Jodi Lee\n",
    "# Maxim Firsov\n",
    "# Hsiang-Yun Lu (Eloise)\n",
    "# Gabriel Aguiar\n",
    "\n",
    "# RESPONSES\n",
    "# - Markdown comments\n",
    "# - Get more docstrings\n",
    "# - Make change so that infile is only read once\n",
    "# - Finish main function\n",
    "\n",
    "# CORRECTIONS\n",
    "# - Made markdown comments\n",
    "# - Made more docstrings and comments\n",
    "# - Infile is only read once in the main function\n",
    "# - Main function was put together"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
